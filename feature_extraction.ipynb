{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29aa30e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipaddress\n",
    "import re\n",
    "import urllib.request\n",
    "from urllib import response\n",
    "\n",
    "#from Demos.win32cred_demo import domain\n",
    "from bs4 import BeautifulSoup\n",
    "import socket\n",
    "import requests\n",
    "from googlesearch import search\n",
    "import whois\n",
    "from datetime import date, datetime\n",
    "import time\n",
    "from dateutil.parser import parse as date_parse\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "from urllib3.util import url\n",
    "\n",
    "\n",
    "class FeatureExtraction:\n",
    "    features = []\n",
    "\n",
    "    def __init__(self, url):\n",
    "        self.features = []\n",
    "        self.url = url\n",
    "        self.domain = \"\"\n",
    "        self.whois_response = \"\"\n",
    "        self.urlparse = \"\"\n",
    "        self.response = \"\"\n",
    "        self.soup = \"\"\n",
    "\n",
    "        try:\n",
    "            self.response = requests.get(url)\n",
    "            self.soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            self.urlparse = urlparse(url)\n",
    "            self.domain = self.urlparse.netloc\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            self.whois_response = whois.whois(self.domain)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        self.features.append(self.UsingIp())\n",
    "        self.features.append(self.longUrl())\n",
    "        self.features.append(self.shortUrl())\n",
    "        self.features.append(self.symbol())\n",
    "        self.features.append(self.redirecting())\n",
    "        self.features.append(self.prefixSuffix())\n",
    "        self.features.append(self.SubDomains())\n",
    "        self.features.append(self.Hppts())\n",
    "        self.features.append(self.DomainRegLen())\n",
    "        self.features.append(self.Favicon())\n",
    "\n",
    "        self.features.append(self.NonStdPort())\n",
    "        self.features.append(self.HTTPSDomainURL())\n",
    "        self.features.append(self.RequestURL())\n",
    "        self.features.append(self.AnchorURL())\n",
    "        self.features.append(self.LinksInScriptTags())\n",
    "        self.features.append(self.ServerFormHandler())\n",
    "        self.features.append(self.InfoEmail())\n",
    "        self.features.append(self.AbnormalURL())\n",
    "        self.features.append(self.WebsiteForwarding())\n",
    "        self.features.append(self.StatusBarCust())\n",
    "\n",
    "        self.features.append(self.DisableRightClick())\n",
    "        self.features.append(self.UsingPopupWindow())\n",
    "        self.features.append(self.IframeRedirection())\n",
    "        self.features.append(self.AgeofDomain())\n",
    "        self.features.append(self.DNSRecording())\n",
    "        self.features.append(self.WebsiteTraffic())\n",
    "        self.features.append(self.PageRank())\n",
    "        self.features.append(self.GoogleIndex())\n",
    "        self.features.append(self.LinksPointingToPage())\n",
    "        self.features.append(self.StatsReport())\n",
    "\n",
    "    # 1.UsingIp\n",
    "    def UsingIp(self):\n",
    "        try:\n",
    "            ipaddress.ip_address(self.url)\n",
    "            return -1\n",
    "        except:\n",
    "            return 1\n",
    "\n",
    "    # 2.longUrl\n",
    "    def longUrl(self):\n",
    "        if len(self.url) < 54:\n",
    "            return 1\n",
    "        if len(self.url) >= 54 and len(self.url) <= 75:\n",
    "            return 0\n",
    "        return -1\n",
    "\n",
    "    # 3.shortUrl\n",
    "    def shortUrl(self):\n",
    "        match = re.search('bit\\.ly|goo\\.gl|shorte\\.st|go2l\\.ink|x\\.co|ow\\.ly|t\\.co|tinyurl|tr\\.im|is\\.gd|cli\\.gs|'\n",
    "                          'yfrog\\.com|migre\\.me|ff\\.im|tiny\\.cc|url4\\.eu|twit\\.ac|su\\.pr|twurl\\.nl|snipurl\\.com|'\n",
    "                          'short\\.to|BudURL\\.com|ping\\.fm|post\\.ly|Just\\.as|bkite\\.com|snipr\\.com|fic\\.kr|loopt\\.us|'\n",
    "                          'doiop\\.com|short\\.ie|kl\\.am|wp\\.me|rubyurl\\.com|om\\.ly|to\\.ly|bit\\.do|t\\.co|lnkd\\.in|'\n",
    "                          'db\\.tt|qr\\.ae|adf\\.ly|goo\\.gl|bitly\\.com|cur\\.lv|tinyurl\\.com|ow\\.ly|bit\\.ly|ity\\.im|'\n",
    "                          'q\\.gs|is\\.gd|po\\.st|bc\\.vc|twitthis\\.com|u\\.to|j\\.mp|buzurl\\.com|cutt\\.us|u\\.bb|yourls\\.org|'\n",
    "                          'x\\.co|prettylinkpro\\.com|scrnch\\.me|filoops\\.info|vzturl\\.com|qr\\.net|1url\\.com|tweez\\.me|v\\.gd|tr\\.im|link\\.zip\\.net',\n",
    "                          self.url)\n",
    "        if match:\n",
    "            return -1\n",
    "        return 1\n",
    "\n",
    "    # 4.Symbol@\n",
    "    def symbol(self):\n",
    "        if re.findall(\"@\", self.url):\n",
    "            return -1\n",
    "        return 1\n",
    "\n",
    "    # 5.Redirecting//\n",
    "    def redirecting(self):\n",
    "        if self.url.rfind('//') > 6:\n",
    "            return -1\n",
    "        return 1\n",
    "\n",
    "    # 6.prefixSuffix\n",
    "    def prefixSuffix(self):\n",
    "        try:\n",
    "            match = re.findall('\\-', self.domain)\n",
    "            if match:\n",
    "                return -1\n",
    "            return 1\n",
    "        except:\n",
    "            return -1\n",
    "\n",
    "    # 7.SubDomains\n",
    "    def SubDomains(self):\n",
    "        dot_count = len(re.findall(\"\\.\", self.url))\n",
    "        if dot_count == 1:\n",
    "            return 1\n",
    "        elif dot_count == 2:\n",
    "            return 0\n",
    "        return -1\n",
    "\n",
    "    # 8.HTTPS\n",
    "    def Hppts(self):\n",
    "        try:\n",
    "            https = self.urlparse.scheme\n",
    "            if 'https' in https:\n",
    "                return 1\n",
    "            return -1\n",
    "        except:\n",
    "            return 1\n",
    "\n",
    "    # 9.DomainRegLen\n",
    "    def DomainRegLen(self):\n",
    "        try:\n",
    "            expiration_date = self.whois_response.expiration_date\n",
    "            creation_date = self.whois_response.creation_date\n",
    "            try:\n",
    "                if (len(expiration_date)):\n",
    "                    expiration_date = expiration_date[0]\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                if (len(creation_date)):\n",
    "                    creation_date = creation_date[0]\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            age = (expiration_date.year - creation_date.year) * 12 + (expiration_date.month - creation_date.month)\n",
    "            if age >= 12:\n",
    "                return 1\n",
    "            return -1\n",
    "        except:\n",
    "            return -1\n",
    "\n",
    "    # 10. Favicon\n",
    "    def Favicon(self):\n",
    "        try:\n",
    "            for head in self.soup.find_all('head'):\n",
    "                for head.link in self.soup.find_all('link', href=True):\n",
    "                    dots = [x.start(0) for x in re.finditer('\\.', head.link['href'])]\n",
    "                    if self.url in head.link['href'] or len(dots) == 1 or self.domain in head.link['href']:\n",
    "                        return 1\n",
    "            return -1\n",
    "        except:\n",
    "            return -1\n",
    "\n",
    "    # 11. NonStdPort\n",
    "    def NonStdPort(self):\n",
    "        try:\n",
    "            port = self.domain.split(\":\")\n",
    "            if len(port) > 1:\n",
    "                return -1\n",
    "            return 1\n",
    "        except:\n",
    "            return -1\n",
    "\n",
    "    # 12. HTTPSDomainURL\n",
    "    def HTTPSDomainURL(self):\n",
    "        try:\n",
    "            if 'https' in self.domain:\n",
    "                return -1\n",
    "            return 1\n",
    "        except:\n",
    "            return -1\n",
    "\n",
    "    # 13. RequestURL\n",
    "    def RequestURL(self):\n",
    "        try:\n",
    "            for img in self.soup.find_all('img', src=True):\n",
    "                dots = [x.start(0) for x in re.finditer('\\.', img['src'])]\n",
    "                if self.url in img['src'] or self.domain in img['src'] or len(dots) == 1:\n",
    "                    success = success + 1\n",
    "                i = i + 1\n",
    "\n",
    "            for audio in self.soup.find_all('audio', src=True):\n",
    "                dots = [x.start(0) for x in re.finditer('\\.', audio['src'])]\n",
    "                if self.url in audio['src'] or self.domain in audio['src'] or len(dots) == 1:\n",
    "                    success = success + 1\n",
    "                i = i + 1\n",
    "\n",
    "            for embed in self.soup.find_all('embed', src=True):\n",
    "                dots = [x.start(0) for x in re.finditer('\\.', embed['src'])]\n",
    "                if self.url in embed['src'] or self.domain in embed['src'] or len(dots) == 1:\n",
    "                    success = success + 1\n",
    "                i = i + 1\n",
    "\n",
    "            for iframe in self.soup.find_all('iframe', src=True):\n",
    "                dots = [x.start(0) for x in re.finditer('\\.', iframe['src'])]\n",
    "                if self.url in iframe['src'] or self.domain in iframe['src'] or len(dots) == 1:\n",
    "                    success = success + 1\n",
    "                i = i + 1\n",
    "\n",
    "            try:\n",
    "                percentage = success / float(i) * 100\n",
    "                if percentage < 22.0:\n",
    "                    return 1\n",
    "                elif ((percentage >= 22.0) and (percentage < 61.0)):\n",
    "                    return 0\n",
    "                else:\n",
    "                    return -1\n",
    "            except:\n",
    "                return 0\n",
    "        except:\n",
    "            return -1\n",
    "\n",
    "    # 14. AnchorURL\n",
    "    def AnchorURL(self):\n",
    "        try:\n",
    "            i, unsafe = 0, 0\n",
    "            for a in self.soup.find_all('a', href=True):\n",
    "                if \"#\" in a['href'] or \"javascript\" in a['href'].lower() or \"mailto\" in a['href'].lower() or not (\n",
    "                        url in a['href'] or self.domain in a['href']):\n",
    "                    unsafe = unsafe + 1\n",
    "                i = i + 1\n",
    "\n",
    "            try:\n",
    "                percentage = unsafe / float(i) * 100\n",
    "                if percentage < 31.0:\n",
    "                    return 1\n",
    "                elif ((percentage >= 31.0) and (percentage < 67.0)):\n",
    "                    return 0\n",
    "                else:\n",
    "                    return -1\n",
    "            except:\n",
    "                return -1\n",
    "\n",
    "        except:\n",
    "            return -1\n",
    "\n",
    "    # 15. LinksInScriptTags\n",
    "    def LinksInScriptTags(self):\n",
    "        try:\n",
    "            i, success = 0, 0\n",
    "\n",
    "            for link in self.soup.find_all('link', href=True):\n",
    "                dots = [x.start(0) for x in re.finditer('\\.', link['href'])]\n",
    "                if self.url in link['href'] or self.domain in link['href'] or len(dots) == 1:\n",
    "                    success = success + 1\n",
    "                i = i + 1\n",
    "\n",
    "            for script in self.soup.find_all('script', src=True):\n",
    "                dots = [x.start(0) for x in re.finditer('\\.', script['src'])]\n",
    "                if self.url in script['src'] or self.domain in script['src'] or len(dots) == 1:\n",
    "                    success = success + 1\n",
    "                i = i + 1\n",
    "\n",
    "            try:\n",
    "                percentage = success / float(i) * 100\n",
    "                if percentage < 17.0:\n",
    "                    return 1\n",
    "                elif ((percentage >= 17.0) and (percentage < 81.0)):\n",
    "                    return 0\n",
    "                else:\n",
    "                    return -1\n",
    "            except:\n",
    "                return 0\n",
    "        except:\n",
    "            return -1\n",
    "\n",
    "    # 16. ServerFormHandler\n",
    "    def ServerFormHandler(self):\n",
    "        try:\n",
    "            if len(self.soup.find_all('form', action=True)) == 0:\n",
    "                return 1\n",
    "            else:\n",
    "                for form in self.soup.find_all('form', action=True):\n",
    "                    if form['action'] == \"\" or form['action'] == \"about:blank\":\n",
    "                        return -1\n",
    "                    elif self.url not in form['action'] and self.domain not in form['action']:\n",
    "                        return 0\n",
    "                    else:\n",
    "                        return 1\n",
    "        except:\n",
    "            return -1\n",
    "\n",
    "    # 17. InfoEmail\n",
    "    def InfoEmail(self):\n",
    "        try:\n",
    "            if re.findall(r\"[mail\\(\\)|mailto:?]\", self.soup):\n",
    "                return -1\n",
    "            else:\n",
    "                return 1\n",
    "        except:\n",
    "            return -1\n",
    "\n",
    "    # 18. AbnormalURL\n",
    "    def AbnormalURL(self):\n",
    "        try:\n",
    "            if self.response.text == self.whois_response:\n",
    "                return 1\n",
    "            else:\n",
    "                return -1\n",
    "        except:\n",
    "            return -1\n",
    "\n",
    "    # 19. WebsiteForwarding\n",
    "    def WebsiteForwarding(self):\n",
    "        try:\n",
    "            if len(self.response.history) <= 1:\n",
    "                return 1\n",
    "            elif len(self.response.history) <= 4:\n",
    "                return 0\n",
    "            else:\n",
    "                return -1\n",
    "        except:\n",
    "            return -1\n",
    "\n",
    "    # 20. StatusBarCust\n",
    "    def StatusBarCust(self):\n",
    "        try:\n",
    "            if re.findall(\"<script>.+onmouseover.+</script>\", self.response.text):\n",
    "                return 1\n",
    "            else:\n",
    "                return -1\n",
    "        except:\n",
    "            return -1\n",
    "\n",
    "    # 21. DisableRightClick\n",
    "    def DisableRightClick(self):\n",
    "        try:\n",
    "            if re.findall(r\"event.button ?== ?2\", self.response.text):\n",
    "                return 1\n",
    "            else:\n",
    "                return -1\n",
    "        except:\n",
    "            return -1\n",
    "\n",
    "    # 22. UsingPopupWindow\n",
    "    def UsingPopupWindow(self):\n",
    "        try:\n",
    "            if re.findall(r\"alert\\(\", self.response.text):\n",
    "                return 1\n",
    "            else:\n",
    "                return -1\n",
    "        except:\n",
    "            return -1\n",
    "\n",
    "    # 23. IframeRedirection\n",
    "    def IframeRedirection(self):\n",
    "        try:\n",
    "            if re.findall(r\"[<iframe>|<frameBorder>]\", self.response.text):\n",
    "                return 1\n",
    "            else:\n",
    "                return -1\n",
    "        except:\n",
    "            return -1\n",
    "\n",
    "    # 24. AgeofDomain\n",
    "    def AgeofDomain(self):\n",
    "        try:\n",
    "            creation_date = self.whois_response.creation_date\n",
    "            try:\n",
    "                if (len(creation_date)):\n",
    "                    creation_date = creation_date[0]\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            today = date.today()\n",
    "            age = (today.year - creation_date.year) * 12 + (today.month - creation_date.month)\n",
    "            if age >= 6:\n",
    "                return 1\n",
    "            return -1\n",
    "        except:\n",
    "            return -1\n",
    "\n",
    "    # 25. DNSRecording\n",
    "    def DNSRecording(self):\n",
    "        try:\n",
    "            creation_date = self.whois_response.creation_date\n",
    "            try:\n",
    "                if (len(creation_date)):\n",
    "                    creation_date = creation_date[0]\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            today = date.today()\n",
    "            age = (today.year - creation_date.year) * 12 + (today.month - creation_date.month)\n",
    "            if age >= 6:\n",
    "                return 1\n",
    "            return -1\n",
    "        except:\n",
    "            return -1\n",
    "\n",
    "    # 26. WebsiteTraffic\n",
    "    def WebsiteTraffic(self):\n",
    "        try:\n",
    "            rank = BeautifulSoup(urllib.request.urlopen(\"http://data.alexa.com/data?cli=10&dat=s&url=\" + url).read(),\n",
    "                                 \"xml\").find(\"REACH\")['RANK']\n",
    "            if (int(rank) < 100000):\n",
    "                return 1\n",
    "            return 0\n",
    "        except:\n",
    "            return -1\n",
    "\n",
    "    # 27. PageRank\n",
    "    def PageRank(self, rank_checker_response=None):\n",
    "        try:\n",
    "            prank_checker_response = requests.post(\"https://www.checkpagerank.net/index.php\", {\"name\": self.domain})\n",
    "\n",
    "            global_rank = int(re.findall(r\"Global Rank: ([0-9]+)\", rank_checker_response.text)[0])\n",
    "            if global_rank > 0 and global_rank < 100000:\n",
    "                return 1\n",
    "            return -1\n",
    "        except:\n",
    "            return -1\n",
    "\n",
    "    # 28. GoogleIndex\n",
    "    def GoogleIndex(self):\n",
    "        try:\n",
    "            site = search(self.url, 5)\n",
    "            if site:\n",
    "                return 1\n",
    "            else:\n",
    "                return -1\n",
    "        except:\n",
    "            return 1\n",
    "\n",
    "    # 29. LinksPointingToPage\n",
    "    def LinksPointingToPage(self):\n",
    "        try:\n",
    "            number_of_links = len(re.findall(r\"<a href=\", self.response.text))\n",
    "            if number_of_links == 0:\n",
    "                return 1\n",
    "            elif number_of_links <= 2:\n",
    "                return 0\n",
    "            else:\n",
    "                return -1\n",
    "        except:\n",
    "            return -1\n",
    "\n",
    "    # 30. StatsReport\n",
    "    def StatsReport(self):\n",
    "        try:\n",
    "            url_match = re.search(\n",
    "                'at\\.ua|usa\\.cc|baltazarpresentes\\.com\\.br|pe\\.hu|esy\\.es|hol\\.es|sweddy\\.com|myjino\\.ru|96\\.lt|ow\\.ly',\n",
    "                url)\n",
    "            ip_address = socket.gethostbyname(self.domain)\n",
    "            ip_match = re.search(\n",
    "                '146\\.112\\.61\\.108|213\\.174\\.157\\.151|121\\.50\\.168\\.88|192\\.185\\.217\\.116|78\\.46\\.211\\.158|181\\.174\\.165\\.13|46\\.242\\.145\\.103|121\\.50\\.168\\.40|83\\.125\\.22\\.219|46\\.242\\.145\\.98|'\n",
    "                '107\\.151\\.148\\.44|107\\.151\\.148\\.107|64\\.70\\.19\\.203|199\\.184\\.144\\.27|107\\.151\\.148\\.108|107\\.151\\.148\\.109|119\\.28\\.52\\.61|54\\.83\\.43\\.69|52\\.69\\.166\\.231|216\\.58\\.192\\.225|'\n",
    "                '118\\.184\\.25\\.86|67\\.208\\.74\\.71|23\\.253\\.126\\.58|104\\.239\\.157\\.210|175\\.126\\.123\\.219|141\\.8\\.224\\.221|10\\.10\\.10\\.10|43\\.229\\.108\\.32|103\\.232\\.215\\.140|69\\.172\\.201\\.153|'\n",
    "                '216\\.218\\.185\\.162|54\\.225\\.104\\.146|103\\.243\\.24\\.98|199\\.59\\.243\\.120|31\\.170\\.160\\.61|213\\.19\\.128\\.77|62\\.113\\.226\\.131|208\\.100\\.26\\.234|195\\.16\\.127\\.102|195\\.16\\.127\\.157|'\n",
    "                '34\\.196\\.13\\.28|103\\.224\\.212\\.222|172\\.217\\.4\\.225|54\\.72\\.9\\.51|192\\.64\\.147\\.141|198\\.200\\.56\\.183|23\\.253\\.164\\.103|52\\.48\\.191\\.26|52\\.214\\.197\\.72|87\\.98\\.255\\.18|209\\.99\\.17\\.27|'\n",
    "                '216\\.38\\.62\\.18|104\\.130\\.124\\.96|47\\.89\\.58\\.141|78\\.46\\.211\\.158|54\\.86\\.225\\.156|54\\.82\\.156\\.19|37\\.157\\.192\\.102|204\\.11\\.56\\.48|110\\.34\\.231\\.42',\n",
    "                ip_address)\n",
    "            if url_match:\n",
    "                return -1\n",
    "            elif ip_match:\n",
    "                return -1\n",
    "            return 1\n",
    "        except:\n",
    "            return 1\n",
    "\n",
    "    def getFeaturesList(self):\n",
    "        return self.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ecac558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flask: 3.1.0\n",
      "numpy: 1.24.4\n",
      "pandas: 1.5.3\n",
      "scikit-learn: 1.2.2\n",
      "matplotlib: 3.7.1\n",
      "seaborn: 0.12.2\n",
      "imblearn: 0.10.1\n",
      "bs4 (BeautifulSoup): 4.12.2\n",
      "requests: 2.31.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thabu\\AppData\\Local\\Temp\\ipykernel_20768\\720622868.py:11: DeprecationWarning: The '__version__' attribute is deprecated and will be removed in Flask 3.1. Use feature detection or 'importlib.metadata.version(\"flask\")' instead.\n",
      "  print(\"flask:\", flask.__version__)\n"
     ]
    }
   ],
   "source": [
    "import flask\n",
    "import numpy\n",
    "import pandas\n",
    "import sklearn\n",
    "import matplotlib\n",
    "import seaborn\n",
    "import imblearn\n",
    "import bs4\n",
    "import requests\n",
    "\n",
    "print(\"flask:\", flask.__version__)\n",
    "print(\"numpy:\", numpy.__version__)\n",
    "print(\"pandas:\", pandas.__version__)\n",
    "print(\"scikit-learn:\", sklearn.__version__)\n",
    "print(\"matplotlib:\", matplotlib.__version__)\n",
    "print(\"seaborn:\", seaborn.__version__)\n",
    "print(\"imblearn:\", imblearn.__version__)\n",
    "print(\"bs4 (BeautifulSoup):\", bs4.__version__)\n",
    "print(\"requests:\", requests.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5eacae75",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'whois' has no attribute '__version__'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdateutil\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01murllib3\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython-whois:\u001b[39m\u001b[38;5;124m\"\u001b[39m, whois\u001b[38;5;241m.\u001b[39m__version__)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython-dateutil:\u001b[39m\u001b[38;5;124m\"\u001b[39m, dateutil\u001b[38;5;241m.\u001b[39m__version__)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124murllib3:\u001b[39m\u001b[38;5;124m\"\u001b[39m, urllib3\u001b[38;5;241m.\u001b[39m__version__)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'whois' has no attribute '__version__'"
     ]
    }
   ],
   "source": [
    "import whois\n",
    "import dateutil\n",
    "import urllib3\n",
    "\n",
    "print(\"python-whois:\", whois.__version__)\n",
    "print(\"python-dateutil:\", dateutil.__version__)\n",
    "print(\"urllib3:\", urllib3.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bee50d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: googlesearch-python\n",
      "Version: 1.3.0\n",
      "Summary: A Python library for scraping the Google search engine.\n",
      "Home-page: https://github.com/Nv7-GitHub/googlesearch\n",
      "Author: Nishant Vikramaditya\n",
      "Author-email: junk4Nv7@gmail.com\n",
      "License: \n",
      "Location: C:\\Users\\thabu\\anaconda3\\Lib\\site-packages\n",
      "Requires: beautifulsoup4, requests\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show googlesearch-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04340743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Package(s) not found: whois\n"
     ]
    }
   ],
   "source": [
    "pip show whois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0501a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
